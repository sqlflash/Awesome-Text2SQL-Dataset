# Awesome-Text2SQL-Dataset
Awesome-Text2SQL-Dataset is a curated collection of datasets specifically designed for the Text-to-SQL task ‚Äî the challenge of converting natural language questions into SQL queries. As a critical component of natural language interfaces to databases (NLIDB), Text2SQL plays a vital role in enabling users to interact with data using everyday language.

This repository aims to provide researchers, developers, and practitioners with a comprehensive list of datasets that support the development and evaluation of Text2SQL models. Whether you‚Äôre exploring schema linking, complex SQL generation, cross-domain generalization, or conversational query generation, you‚Äôll find relevant datasets here to accelerate your work.

We welcome contributions to keep this list up-to-date and useful for the community.

## üÜï Latest Datasets (2025)

Recent datasets that introduce new challenges such as data synthesis, error correction, and ambiguous query resolution. These datasets reflect the newest trends and tasks in Text2SQL research.

| Dataset                  | Link                                                                                                          | Desc |
|--------------------------|---------------------------------------------------------------------------------------------------------------|------|
| TINYSQL             | [[Paper](https://arxiv.org/html/2503.12730)][[Dateset](https://huggingface.co/collections/withmartian/tinysql-6760e92748b63fa56a6ffc9f)] | Small, diverse benchmark for lightweight evaluation |
| NL2SQL-Bugs         | [[Paper](https://arxiv.org/pdf/2503.11984)][[Dateset](https://github.com/HKUSTDial/NL2SQL-Bugs-Benchmark)]                                                                  | Dataset with extensive SQL syntax errors for robustness testing |
| OmniSQL            | [[Paper](https://arxiv.org/html/2503.02240)][[Dateset](https://huggingface.co/datasets/seeklhy/SynSQL-2.5M)]                                                                 | Massively synthetic SQL corpus built via templated generation |
| synthetic_text_to_sql | [[Dataset](https://huggingface.co/datasets/gretelai/synthetic_text_to_sql)]                             | Large-scale synthetic Text2SQL dataset |

## üóÇÔ∏è Datasets

These datasets focus on specific domains such as healthcare, finance, programming, and linguistics. They help evaluate how well Text2SQL systems generalize to specialized fields or languages.

| Dataset        | Link                                                                                                                   | Desc                         |
|------------|----------------------------------------------------------------------------------------------------------------------------|------------------------------|
| WikiSQL    | [[paper](https://arxiv.org/pdf/1709.00103.pdf)][[dataset](https://github.com/salesforce/WikiSQL)]                          |2017/09, Salesforce proposes a large Text-to-SQL dataset WikiSQL, the data comes from Wikipedia, which belongs to a single domain, contains 80,654 natural language questions, and 77,840 SQL statements. The form of SQL statements is relatively simple, and does not include sorting, grouping, and subqueries and other complex operations.         |
| Spider 1.0 |[[paper](https://arxiv.org/pdf/1809.08887.pdf)][[Leaderboard](https://yale-lily.github.io/spider)]                          | 2018/09, Yale University proposes the Text-to-SQL dataset Spider with multiple databases, multiple tables, and single-round query. It is also recognized as the most difficult large-scale cross-domain evaluation list in the industry. It contains 10,181 natural language questions and 5,693 SQL statements |
| SParC      |[[paper](https://arxiv.org/pdf/1906.02285.pdf)][[Leaderboard](https://yale-lily.github.io/sparc)]                           |2019/06, Yale University proposes a large dataset SParC for complex, cross-domain, and context-dependent(multi-turn) semantic parsing and text-to-SQL task, which consists of 4,298 coherent question sequences (12k+ unique individual questions annotated with SQL queries annotated by 14 Yale students), obtained from user interactions with 200 complex databases over 138 domains. |
|CSpider     |[[paper](https://arxiv.org/pdf/1906.02285.pdf)][[Leaderboard](https://taolusi.github.io/CSpider-explorer/)]                 |2019/09, Westlake University propposes a large Chinese dataset CSpider for complex and cross-domain semantic parsing and text-to-SQL task, translated from Spider by 2 NLP researchers and 1 computer science student, which consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains. |
| CoSQL      | [[Paper](https://ar5iv.labs.arxiv.org/html/1909.05378)][[Leaderboard](https://yale-lily.github.io/cosql)]                  |2019/09, Yale University and Salesforce Research propose a cross-domain database CoSQL, which consists of 30k+ turns plus 10k+ annotated SQL queries, obtained from a Wizard-of-Oz (WOZ) collection of 3k dialogues querying 200 complex DBs spanning 138 domains. |
|KaggleDBQA  |[[paper](https://arxiv.org/abs/2106.11455)][[dataset](https://github.com/Chia-Hsuan-Lee/KaggleDBQA/)]                       |2021/06, KaggleDBQA is a challenging cross-domain and complex evaluation dataset of real Web databases, with domain-specific data types, original formatting, and unrestricted questions. |
| Spider-Syn | [[Paper](https://ar5iv.labs.arxiv.org/html/2106.01065)][[dataset](https://github.com/ygan/Spider-Syn)]                     | 2021/06, Spider-Syn is a benchmark dataset designed to evaluate and enhance the robustness of Text-to-SQL models against synonym substitutions in natural language questions. Developed by researchers from Queen Mary University of London and collaborators, Spider-Syn is based on the original Spider dataset. |
| SEDE       |[[Paper](https://ar5iv.labs.arxiv.org/html/2106.05006)][[dataset](https://github.com/hirupert/sede)]                        | 2021/06, SEDE (Stack Exchange Data Explorer) is new dataset for Text-to-SQL tasks with more than 12,000 SQL queries and their natural language description. It's based on a real usage of users from the Stack Exchange Data Explorer platform, which brings complexities and challenges never seen before in any other semantic parsing dataset like including complex nesting, dates manipulation, numeric and text manipulation, parameters, and most importantly: under-specification and hidden-assumptions.|
|CHASE       |[[paper](https://aclanthology.org/2021.acl-long.180.pdf)][[dataset](https://github.com/xjtu-intsoft/chase)]                 |2021/08, CHASE is a large-scale and pragmatic Chinese dataset for cross-database context-dependent text-to-SQL task (natural language interfaces for relational databases). It is released along with our ACL 2021 paper: CHASE: A Large-Scale and Pragmatic Chinese Dataset for Cross-Database Context-Dependent Text-to-SQL.|
| Spider-DK  | [[Paper](https://ar5iv.labs.arxiv.org/html/2109.05157)][[dataset](https://github.com/ygan/Spider-DK)]                      | 2021/09, Spider-DK is a benchmark dataset designed to evaluate and enhance the robustness of Text-to-SQL models when handling domain knowledge. Developed by researchers from Queen Mary University of London, Spider-DK builds upon the original Spider dataset |
| EHRSQL     |[[Paper](https://arxiv.org/html/2301.07695)][[dataset](https://github.com/glee4810/EHRSQL)]                                 | 2023/01, EHRSQL is a large-scale, high-quality dataset designed for text-to-SQL question answering on Electronic Health Records from MIMIC-III and eICU. The dataset includes questions collected from 222 hospital staff, such as physicians, nurses, insurance reviewers, and health records teams. |
|BIRD-SQL    |[[paper](https://arxiv.org/pdf/2305.03111.pdf)][[Leaderboard](https://bird-bench.github.io/)]                               |2023/05, the University of Hong Kong and Alibaba propose a large-scale cross-domain dataset BIRD, which contains over 12,751 unique question-SQL pairs, 95 big databases with a total size of 33.4 GB. It also covers more than 37 professional domains, such as blockchain, hockey, healthcare and education, etc.|
| UNITE      | [[Paper](https://ar5iv.labs.arxiv.org/html/2305.16265)][[dataset](https://github.com/awslabs/unified-text2sql-benchmark)]] |2023/05, Unified benchmark is composed of 18 publicly available text-to-SQL datasets, containing natural language questions from more than 12 domains, SQL queries from more than 3.9K patterns, and 29K databases. Compared to the widely used Spider benchmark, we introduce ‚àº120K additional examples and a threefold increase in SQL patterns, such as comparative and boolean questions. |
| Archer     | [[Paper](https://arxiv.org/html/2402.12554)]  [[Leaderboard](https://sig4kg.github.io/archer-bench/)]                      | 2024/02, Archer is a challenging bilingual text-to-SQL dataset specific to complex reasoning, including arithmetic, commonsense and hypothetical reasoning. It contains 1,042 English questions and 1,042 Chinese questions, along with 521 unique SQL queries, covering 20 English databases across 20 domains.| 
| BookSQL    | [[Paper](https://arxiv.org/html/2406.07860)][[dataset](https://github.com/Exploration-Lab/BookSQL)]]                       | 2024/06, BookSQL has 100k Query-SQL pairs which is about 1.25 times the existing largest Text-2-SQL dataset: WikiSQL. In particular, for designing the queries, we consulted financial experts to understand various practical use cases. We also plan to create a leaderboard where researchers can benchmark various Text-to-SQL models for the accounting domain. |
|Spider 2.0  |[[paper](https://spider2-sql.github.io/)] [[Leaderboard](https://spider2-sql.github.io/)]                                   |2024/08, Spider 2.0, proposed by XLang AI, serves as an advanced evaluation framework for text-to-SQL tasks within real-world enterprise-level workflows. It contains 600 complex text-to-SQL workflow problems, derived from various enterprise database use cases. The dataset includes databases sourced from actual data applications, often containing over 1,000 columns, and stored in cloud or local systems like BigQuery, Snowflake, or PostgreSQL.|
| BEAVER     |[[Paper](https://arxiv.org/html/2409.02038)[[dataset](https://github.com/peterbaile/beaver)]]                               | 2024/09, BEAVER, sourced from real enterprise data warehouses together with natural language queries and their correct SQL statements which we collected from actual user history|
| PRACTIQ    | [[Paper](https://arxiv.org/html/2410.11076)]                                                                               |2024/10, PRACTIQ: A Practical Conversational text-to-SQL dataset with Ambiguous and Unanswerable Queries |
| TURSpider  | [[Paper](https://ieeexplore.ieee.org/document/10753591)][[dataset](https://github.com/alibugra/TURSpider)]                 | 2024/11ÔºåTURSpider is a novel Turkish Text-to-SQL dataset that includes complex queries, akin to those in the original Spider dataset. TURSpider dataset comprises two main subsets: a dev set and a training set, aligned with the structure and scale of the popular Spider dataset. The dev set contains 1034 data rows with 1023 unique questions and 584 distinct SQL queries. In the training set, there are 8659 data rows, 8506 unique questions, and corresponding SQL queries. |
